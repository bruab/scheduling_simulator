NOTES: All results contained in the 'results/' folder; only summaries and highlights are presented here. The shell script 'scripts/build_all_executables.sh' first removes all executables and then compiles them.


###########
Question 1:

Here are the timings from a 100-processor ring:

default: 3.181
naive: 10.030
ring: 8.854

My implementations are pretty terrible compared with the default MPI_Bcast. "Ring" offers little improvement over "naive". I'm not sure what reason I would have postulated for this phenomenon if I'd answered this question before implementing the rest of the program, but in all my wisdom I must attribute it to some sort of pipelining in the default broadcast. 


###########
Question 2:

Here are the best chunk sizes for 25, 50 and 100 host platforms:

#hosts 	chunk_size 	time
------ 	---------- 	----
25 	2000000 	0.641
50 	1000000 	0.684
100 	1000000 	0.834

(all results in file 'results/question2'.)

The largest chunk size results in no pipelining at all; I wouldn't expect it to be optimal. The smallest chunk size results in sending so many chunks that maybe the overhead of checking the chunk index, calculating the current memory address, initiating and closing communications, etc. begins to be problematic. Here is a comparison of performance of this pipelined broadcast on a 100-processor ring using different chunk sizes:

chunk_size	time
---------- 	----
100000000 	8.853
(one chunk)

1000000 	0.834
(optimal)

Using the ideal chunk size, we get a speedup of 10.62, which is great. The pipelined implementation also offers significant performance improvements over the default broadcast (for chunk_size < NUM_BYTES, anyway). 


###########
Question 3:

Here are the best chunk sizes for 25, 50 and 100 host platforms:

#hosts 	chunk_size 	time 
------ 	---------- 	----
25 	1000000 	0.538
50 	1000000 	0.576
100 	1000000 	0.726

(all results in file 'results/question3'.)

These times are improved over the blocking send implemented for question 2, but only slightly. The chunk size did change for the 25-host platform, but not by a large amount. (The performance for the optimal chunk size chosen for the 'blocking-pipelined' implementation was still quite good.)

Here is a comparison of the speedups:

#hosts 	speedup (with optimal chunk size taken in each case)
------ 	-------
25 	1.19
50 	1.19
100 	1.15

This suggests that the already-not-impressive speedup obtained from asyncrhonous communication may be less with larger systems, though we'd need more data to say so with any confidence.

Finally, the ideal-chunk-sized asynchronous pipelined ring broadcast implementation is 4.38 times faster than the default MPI_Bcast.


###########
Question 4:

The timing for bcast_default is 1.672.

Here are the timings for bcast_ring_pipelined_isend and bcast_bintree_pipelined_isend:

executable	chunk_size	time
---------- 	---------- 	----
ring		100000		3.487
ring		200000		2.259
ring		500000		1.695
ring		1000000		1.606
ring		2000000		1.628
ring		10000000	2.297
ring		100000000	8.934
bintree		100000		0.741
bintree		200000		0.625
bintree		500000		0.556
bintree		1000000		0.533
bintree		2000000		0.525
bintree		10000000	0.547
bintree		100000000	0.927

So on a tree platform, 'ring' has an optimal chunk size of 1,000,000 and 'bintree' is optimized at chunk_size=2,000,000. 'Ring' outperforms the default broadcast ... barely ... for the optimal chunk size. For most other chunk sizes it is markedly worse. The 'bintree' implementation, on the other hand, offers a speedup of as much as 3.18 over the default. With the implementation complete, it's easy for me to say that it was worth it. If I had to do it all over again, I might argue that 1.672 is a pretty good time after all ...


###########
Question 5:

Here are the times for the default broadcast:

network		time
-------		----
fattree		0.695
cluster		0.607

...and here are the best times for the 'ring' and 'bintree' implementations (optimal chunk sizes):

network 	version 	time
------- 	------- 	----
fattree 	ring 		0.720
fattree 	bintree 	1.472
cluster 	ring 		0.616
cluster 	bintree 	0.605

This is kind of heartbreaking at the moment, but encouraging for the long term. It would seem that implementing broadcast offers little or no performance gain on 'real' clusters. The other side of that statement, of course, is just use default and relax.

Overall, it seems that if a very specific network topology is used, and performance is so critical that it is worth developer headaches to obtain any improvement whatsoever, it is advisable to implement like crazy. In most applications, who may be run on various network topologies, it seems like the default implementation is the way to go.

